### 090621 数据集数量对不上的问题 

我自己做的数据集里边，train数据集的句子数量是28514，而根据论文，句子数量应该是27823，平白多出691个句子，这不是一个能够忽略的数量。

```
>>> [(i,s) for (i,s) in enumerate(trains) if len(s) < 5]
>>> [(27, '――'), (226, '――'), (349, 'やがて、'), (520, '……」'), (612, '「そう。'), (713, 'すると、'), (901, '「なぜ」'), (1036, '三四郎は'), (1158, '……'), (1187, '――'), ...]
```

根据这个输出结果我们发现了几个问题。

1. 我分割句子的办法是先通过换行符，然后通过句号。奇怪的是有些段落最后面会带上奇怪的符号。
2. 作者写作的时候经常会: そこで、 分行 然后写对话

方案1： 不再根据换行来分句，而是通过模式识别，以句号和问号分句。 (24776。这个效果还行，但是)
方案2： 不再根据换行来分句，而是通过模式识别，以句号分句。在此之上，设定每组对话符号为一个句子 (舍弃，因为有时候一组对话符号会对应到许多行，而这种情况显然应该以换行分句)
方案3： 先根据\u3000来分句，不再根据换行来分句，而是通过模式识别，以句号和问号分句


