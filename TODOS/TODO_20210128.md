# 方向转变之后

现在主要的任务就是段落分割了

# TODO

- [ ] 编码Focus Loss + BERT小说段落分割
  - [ ] Focus Loss
    - [X] 弄明白Focus Loss
    - [ ] 要对FL和BCE做个对比, 不过是实装时候的事情了
  - [X] 准备数据集
    - [X] 将小节title去掉
- [ ] 看完Long range arena之后开始开始编码
  - [X] 看完Long range arena
  - [ ] 首先把对照实验组给编码出来吧，用bert + FL那个
- [ ] 实验，用手写Transformer来和之前的BiLSTM对比
  - [X] 看论文考虑用sinsoid还是其他什么方法把位置信息考虑进来 (sinsoid很重要，看看pytorch怎么整)
  - [ ] 用Twitter Sentiment Analysis数据集实验自己的Transformer, 用LSTM作为BaseLine (Doing...)
  - [ ] 实验，用GRU来和之前的BiLSTM对比
  - [ ] Batch bert
- [ ] 想办法搞定日语Bert


