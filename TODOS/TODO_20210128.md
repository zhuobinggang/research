# 方向转变之后

现在主要的任务就是段落分割了

# TODO

- [X] 编码快速迭代项目, 使用wiki2vec+LSTM, 同时作为对照组
- [X] 找论文，超长sequence怎么处理 
- [ ] 看论文
  - [X] 先看kernel function那篇
  - [ ] 然后继续深究TF are RNN那篇
- [X] 现在问题在于，理论上finetune三次就能用，可是为什么我精度还是那么低？?????????????????
  - [X] 答案就是精度计算方法错了
  - [X] 确定一下，有没有去掉开头的字符？ (有的，在getitem的时候有做)
  - [X] 检验loss函数有没有正确 (大概是正确的)
  - [ ] 因为命中高了所以精度低是正常的, 得调整参数，大概是因为阿尔法1太大了, 将参数弄成2和1
  - [ ] 还有可能是因为情报不足，将窗口提高到2个句子
  - [ ] 结果没那么恶心之后, 换一个bert，用黑桥研究室的bert+juman
  - [ ] 最不济的情况下，试验固定数量token，完全照搬谷歌实验
  - [ ] 我不确定正确使用了mecab，这个可能会影响性能，不如直接用黑桥大的那个，回去之前训练两回


# Done

- [X] 编码Focus Loss + BERT小说段落分割
  - [X] Focus Loss
    - [X] 弄明白Focus Loss
    - [X] 要对FL和BCE做个对比, 不过是实装时候的事情了
  - [X] 准备数据集
    - [X] 将小节title去掉
  - [X] 实装
    - [X] 将dataset整成什么样子? s, label, s, label ... 这样吗？ 初始化ds的时候就要做手脚，首先确定window size，返回的inpts & labels，inpts: (left ss,  right ss), labels: 0 / 1
    - [X] 通过sbert获取句子embedding
    - [X] 将所有句子embedding存到db里
    - [X] 训练并得到数值
- [X] 看完Long range arena之后开始开始编码
  - [X] 看完Long range arena
  - [X] 首先把对照实验组给编码出来吧，用bert + FL那个
- [X] 实验，用手写Transformer来和之前的BiLSTM对比
  - [X] 看论文考虑用sinsoid还是其他什么方法把位置信息考虑进来 (sinsoid很重要，看看pytorch怎么整)
  - [X] Batch bert
- [X] 实验记录 
  - BERT without FL 全部判断0了，杀你吗 
  - 看来主要是learning rate的原因
- [X] 收集数据集情报: Train(28513:3897), Test(11242:1997)
- [X] 想办法搞定日语Bert
  - [X] 输入句子，输出CLS对应的embedding
  - [X] 检查全部params量，检查可训练params量 (一亿，草，全都可以训练)
  - [X] 训练1epoch，记录时间 (大约2个半小时1epoch, 显然不利于快速迭代, 如果1epoch之后的结果还行，就暂时放一下，用tough to beat来快速整一波) (1 epoch: Trained! Epochs: 1, Batch size: 8, dataset length: 28513, Time cost: 10018.348648071289 seconds) (Trained! Epochs: 1, Batch size: 8, dataset length: 28513, Time cost: 8215.027804136276 seconds)
  - [X] 测试时间: 15:38 -> 15:49

# 实验记录

- [X] cat sentence vs cross seg (3 epochs)
  - [X] cat sentence: (0.45407411460888797, 0.8591887564490304, 0.2804206309464196, 0.4228365540865826), (0.3637034244633242, 0.8418430884184309, 0.2919379068602904, 0.43353330168894144), (0.2515744191453679, 0.8719089130048034, 0.44066099148723087, 0.5854411940672104) 
  - [X] cross seg: (0.4695902356529167, 0.8830279309731365, 0.6059088632949424, 0.7186798687134688), (0.3942240901061479, 0.8789361323607899, 0.6654982473710566, 0.7574688355989067), (0.3361349872244211, 0.8429994662871375, 0.7155733600400601, 0.7740773487300955)
- [ ] cat sentence vs cross seg (3 -> 6 epochs) (Waiting...)
- [ ] wiki2vec 1 sentence perside vs wiki2vec 2 sentence perside (5 epochs)


# Waiting


# 记录

* 数据集情报: Train(28513:3897), Test(11242:1997)

# 思考

* 现在要做的，为了加快迭代，将bert换成word2vec+LSTM获取句子embedding，统计1epoch的精度，和bert做个简单对比
* 思考，影响实验精度的思考: 
  - 1）[CLS] + [SEG] 的方法应该是无可厚非的，因为谷歌在用，为什么我不能用? 而我的实验和他的实验的唯一区别是，我用一个句子作为输入，而谷歌是用两边固定数量的token来作为输入，因此SEG可以稳定处于中间，这理论上是要影响性能的
  - 2) 如果用交叉分割，就要保证[SEG]在中间，如果用句子CLS token，那就要考虑别的做法, 现在能够想到的是concat然后正常minify
  - 3) 能够快速实现的是2，应当做个实验，单句子实验，9个epoch。期望是：loss 下降的比原来要快，其他数值上升也比较快
  - 4) 3当然要训练，但是这是5号晚上的事情了。因为层级BERT理论上是要比普通bert好的（从谷歌实验可以看出），所以基本上走这条路线没有问题。而这条路的前方是我应该到达的。为了加快迭代，用wiki2vec来代替bert作为实验套装
* 现在问题在于，理论上finetune三次就能用，可是为什么我精度还是那么低？?????????????????
  - 因为命中高了所以精度低是正常的, 得调整参数，大概是因为阿尔法1太大了
  - 还有可能是因为情报不足，将窗口提高到2个句子
  - 结果没那么恶心之后, 换一个bert，用黑桥研究室的bert+juman
  - 最不济的情况下，试验固定数量token，完全照搬谷歌实验


